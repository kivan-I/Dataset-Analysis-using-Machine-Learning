{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "53e0a4c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymongo[srv] in c:\\users\\kivan\\anaconda3\\lib\\site-packages (4.4.1)\n",
      "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in c:\\users\\kivan\\anaconda3\\lib\\site-packages (from pymongo[srv]) (2.4.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pymongo[srv]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3a5d5637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in c:\\users\\kivan\\anaconda3\\lib\\site-packages (1.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c1a27e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f280c8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to MongoDB\n",
    "client = MongoClient('mongodb+srv://kivanilangakoon0:KfUpdlmDdEjDL3LB@cluster0.ekvumgd.mongodb.net/')\n",
    "db = client[\"ECommerce\"]\n",
    "clothing = db[\"Clothing\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b91c3562",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Kivan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Kivan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e5573b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing\n",
    "def preprocess_text(review_text):\n",
    "    if 'Review Text' in review_text:\n",
    "        text = review_text['Review Text'].lower()\n",
    "        text = text.replace('.', '').replace(',', '').replace('!', '').replace('?', '')\n",
    "        words = word_tokenize(text)\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        words = [word for word in words if word not in stop_words]\n",
    "        stemmer = PorterStemmer()\n",
    "        words = [stemmer.stem(word) for word in words]\n",
    "        processed_text = ' '.join(words)\n",
    "        return processed_text\n",
    "    else:\n",
    "        return ''  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2033a986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare reviews for sentiment classification\n",
    "reviews = []\n",
    "labels = []\n",
    "for review in clothing.find():\n",
    "    processed_review = preprocess_text(review)\n",
    "    if processed_review:\n",
    "        reviews.append(processed_review)\n",
    "        labels.append(review['Recommended IND'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "60aefa01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the labels to numpy array for better compatibility with scikit-learn\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7582fd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement Feature Extraction (Bags-of-Words)\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2732292c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model = MultinomialNB()\n",
    "model.fit(X, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fe275e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that the model is trained and can be used for predicting new reviews\n",
    "\n",
    "# Example 1 of a new review\n",
    "\n",
    "new_review = \"This dress is amazing!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "757f85ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the new review\n",
    "processed_new_review = preprocess_text({'Review Text': new_review})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "830334ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the preprocessed new review to a feature vector\n",
    "new_review_vector = vectorizer.transform([processed_new_review])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cb71dcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the sentiment of the new review based on the trained data\n",
    "predicted_sentiment = model.predict(new_review_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "84115bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Sentiment: positive\n"
     ]
    }
   ],
   "source": [
    "# Map the predicted sentiment to \"positive\" or \"negative\"\n",
    "if predicted_sentiment[0] == 0:\n",
    "    predicted_category = \"negative\"\n",
    "else:\n",
    "    predicted_category = \"positive\"\n",
    "\n",
    "print(\"Predicted Sentiment:\", predicted_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "20216af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2 of another new review\n",
    "\n",
    "new_review2 = \"I am very disappointed.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2deabbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the new review\n",
    "processed_new_review2 = preprocess_text({'Review Text': new_review2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "41316e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the preprocessed new review to a feature vector\n",
    "new_review_vector2 = vectorizer.transform([processed_new_review2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "562ce157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the sentiment of the new review\n",
    "predicted_sentiment2 = model.predict(new_review_vector2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "44fc5686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Sentiment for new review 2: negative\n"
     ]
    }
   ],
   "source": [
    "# Map the predicted sentiment to \"positive\" or \"negative\"\n",
    "if predicted_sentiment2[0] == 0:\n",
    "    predicted_category2 = \"negative\"\n",
    "else:\n",
    "    predicted_category2 = \"positive\"\n",
    "\n",
    "print(\"Predicted Sentiment for new review 2:\", predicted_category2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c00e6e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Data into Training and Testing Sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d9a926c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the Model (using Naive Bayes as an example)\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "acb92829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Predictions on Test Data\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fdc77d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Model Performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "65354a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 90.00%\n",
      "Precision: 92.86%\n",
      "Recall: 96.30%\n",
      "F1-score: 94.55%\n"
     ]
    }
   ],
   "source": [
    "# Print the evaluation metrics\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy * 100))\n",
    "print(\"Precision: {:.2f}%\".format(precision * 100))\n",
    "print(\"Recall: {:.2f}%\".format(recall * 100))\n",
    "print(\"F1-score: {:.2f}%\".format(f1 * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7684ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
